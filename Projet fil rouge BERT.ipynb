{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e46e2d3-5ea5-4794-afdd-0aef6fdaf181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from transformers import CamembertModel, CamembertTokenizer\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d619b9e-d6ce-4f90-b634-7b452b804982",
   "metadata": {},
   "source": [
    "## Récupération du dataset et filtres de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e47629-e3f1-4059-9507-26b938f20a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8019, 12)\n"
     ]
    }
   ],
   "source": [
    "# Données à récupérer via le fichier movies.csv\n",
    "path = \"Documents/Cours/Cours Simplon/Projet fil rouge - développer un moteur de recommandation de film/movies.csv\"\n",
    "data = pd.read_csv(\"movies.csv\")\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d197df-f4b8-427e-a8ba-d621b0c82c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un dataframe\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8508bd1-78dd-40f5-b8d3-2e277301ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le modèle spaCy pour le français\n",
    "nlp = spacy.load(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2817fe-06a0-4495-86bc-074b20d8c825",
   "metadata": {},
   "source": [
    "## Chargement du modele BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ac0b12-2fa9-4791-a7a0-d109c462cee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6608b93decb44ccb8f809c85888807f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Leo\\anaconda3\\envs\\myenv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Leo\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bebf52720549b8bfda20ece0814b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84ac116c6d504d74bbe4d67346a1436f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c48a1eea184bc8a7dc8c7880f91271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger le tokenizer et le modèle CamemBERT pré-entraîné\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base')\n",
    "model_camembert = CamembertModel.from_pretrained('camembert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efc06f7-abff-4351-88d7-b749ace1f77f",
   "metadata": {},
   "source": [
    "## Pretraitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5faa489b-d9a2-4246-92eb-0f8d78ff7d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des données textuelles avec spaCy\n",
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e382615-934a-4936-8961-0efe04c0b750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le prétraitement aux descriptions des films\n",
    "data['processed_description'] = data['desc_fr'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05a45007-3045-482b-98d5-cd28ae0bb3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding des descriptions de films avec CamemBERT\n",
    "embeddings = []\n",
    "\n",
    "for desc in data['processed_description']:\n",
    "    inputs = tokenizer(desc, return_tensors=\"pt\")\n",
    "    outputs = model_camembert(**inputs)\n",
    "    embeddings.append(outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12efa9f-5c9d-4d2f-b12f-50f1de85e73e",
   "metadata": {},
   "source": [
    "## Modele BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e229162-9e98-46e7-83ff-96cf5a3e9ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour obtenir les recommandations de films avec CamemBERT\n",
    "def get_recommendations_camembert(movie_title, n=5):\n",
    "    # Trouver l'indice du film dans le dataframe\n",
    "    movie_index = data[data['titre'] == movie_title].index[0]\n",
    "\n",
    "    # Obtenir l'embedding CamemBERT du film\n",
    "    movie_embedding = embeddings[movie_index]\n",
    "\n",
    "    # Calcul de la similarité cosinus avec toutes les autres descriptions\n",
    "    similarities = cosine_similarity(movie_embedding.reshape(1, -1), embeddings).flatten()\n",
    "\n",
    "    # Trier les indices par ordre décroissant de similarité\n",
    "    related_movies_indices = similarities.argsort()[::-1]\n",
    "\n",
    "    # Exclure le film lui-même de la liste des recommandations\n",
    "    related_movies_indices = [i for i in related_movies_indices if i != movie_index]\n",
    "\n",
    "    # Récupérer les titres des films recommandés\n",
    "    recommendations = data['titre'].iloc[related_movies_indices][:n].tolist()\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03d41f4b-54d5-41bb-b058-19fb9cc1935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommandations pour 'Oppenheimer' avec CamemBERT:\n",
      "1. Le quatrième protocole\n",
      "2. Sunshine\n",
      "3. Le prodige\n",
      "4. In the Loop\n",
      "5. Good Night, and Good Luck\n"
     ]
    }
   ],
   "source": [
    "# Exemple d'utilisation avec CamemBERT\n",
    "movie_title = 'Oppenheimer'\n",
    "recommendations_camembert = get_recommendations_camembert(movie_title)\n",
    "print(f\"Recommandations pour '{movie_title}' avec CamemBERT:\")\n",
    "for i, title in enumerate(recommendations_camembert):\n",
    "    print(f\"{i+1}. {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a087400e-104a-4ff3-858d-d60ec6d3e4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('save_pretrained\\\\tokenizer_config.json',\n",
       " 'save_pretrained\\\\special_tokens_map.json',\n",
       " 'save_pretrained\\\\sentencepiece.bpe.model',\n",
       " 'save_pretrained\\\\added_tokens.json')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enregistrement du modèle CamemBERT\n",
    "model_camembert.save_pretrained('save_pretrained')\n",
    "\n",
    "# Enregistrement du tokenizer CamemBERT\n",
    "tokenizer.save_pretrained('save_pretrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fef04a-f6e9-46ab-a004-4b0095b6c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
